{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import gzip\n",
    "import gensim.downloader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "from model import SimpleAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sfile):\n",
    "        d = pickle.load(open(sfile, 'rb'))\n",
    "        \n",
    "        self.sentences = d['sentences']\n",
    "        self.indices = d['sub_indices']\n",
    "        \n",
    "        for sent in self.sentences:\n",
    "            for i, word in enumerate(sent):\n",
    "                sent[i] = word.lower().replace(\"'\", \"\")\n",
    "                if sent[i] == '':\n",
    "                    del sent[i]\n",
    "        \n",
    "        self.glove = gensim.downloader.load('glove-wiki-gigaword-200')\n",
    "        \n",
    "        self.sentence_embeddings = []\n",
    "        \n",
    "        for sent in self.sentences:\n",
    "            temp = []\n",
    "            for word in sent:\n",
    "                if word in self.glove:\n",
    "                    temp.append(self.glove[word])\n",
    "            self.sentence_embeddings.append(np.array(temp))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.sentence_embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.sentences[idx], self.sentence_embeddings[idx], self.indices[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WordDataset('subdata.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10491.800028324127\n",
      "10289.15780210495\n",
      "10062.086075663567\n",
      "9835.252136707306\n",
      "9624.863267838955\n",
      "9434.525323271751\n",
      "9245.603696882725\n",
      "9038.808286100626\n",
      "8899.145880550146\n",
      "8800.33431956172\n",
      "8730.941065073013\n",
      "8679.997298270464\n",
      "8637.81130796671\n",
      "8598.927635222673\n",
      "8563.787618815899\n",
      "8532.724863529205\n",
      "8503.52269089222\n",
      "8476.552208989859\n",
      "8452.615196824074\n",
      "8429.00962227583\n",
      "8406.9192443192\n",
      "8386.21566566825\n",
      "8366.248629689217\n",
      "8347.198793113232\n",
      "8328.732744246721\n",
      "8311.244562476873\n",
      "8294.563530921936\n",
      "8279.147120296955\n",
      "8264.529611945152\n",
      "8251.712412387133\n",
      "8238.26609635353\n",
      "8228.707840234041\n",
      "8216.525311291218\n",
      "8207.523184090853\n",
      "8198.043177068233\n",
      "8189.5745559334755\n",
      "8181.149402856827\n",
      "8174.284198731184\n",
      "8165.919034898281\n",
      "8158.627004683018\n",
      "8151.622816860676\n",
      "8145.710460275412\n",
      "8138.279657155275\n",
      "8132.270674645901\n",
      "8125.916241884232\n",
      "8120.878903865814\n",
      "8114.144846647978\n",
      "8108.331323415041\n",
      "8102.998427391052\n",
      "8098.113842129707\n",
      "8092.157411187887\n",
      "8087.759864360094\n",
      "8082.242722094059\n",
      "8077.952939063311\n",
      "8072.407413512468\n",
      "8068.3377857506275\n",
      "8063.221042186022\n",
      "8059.406848788261\n",
      "8054.264911025763\n",
      "8050.4688284397125\n",
      "8045.805322110653\n",
      "8042.188854187727\n",
      "8037.688555151224\n",
      "8034.213282704353\n",
      "8029.830095231533\n",
      "8026.5479593575\n",
      "8022.369528532028\n",
      "8019.125828802586\n",
      "8015.133144944906\n",
      "8011.926109224558\n",
      "8008.169138669968\n",
      "8004.990876168013\n",
      "8001.435721904039\n",
      "7998.279285490513\n",
      "7994.929896444082\n",
      "7991.812613606453\n",
      "7988.62746104598\n",
      "7985.5462709367275\n",
      "7982.471657514572\n",
      "7979.452961474657\n",
      "7976.455234467983\n",
      "7973.511037290096\n",
      "7970.585753321648\n",
      "7967.698786020279\n",
      "7964.833034694195\n",
      "7961.9968920350075\n",
      "7959.187316417694\n",
      "7956.406409084797\n",
      "7953.652010917664\n",
      "7950.926114857197\n",
      "7948.224746316671\n",
      "7945.550691664219\n",
      "7942.900716781616\n",
      "7940.277600646019\n",
      "7937.680267393589\n",
      "7935.1107985675335\n",
      "7932.568725913763\n",
      "7930.054586678743\n",
      "7927.567217022181\n",
      "7925.105259537697\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda')\n",
    "model = SimpleAttention(200, 20)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    accum = 0\n",
    "    for i in range(len(train_dataset)):\n",
    "        text, embed, ind = train_dataset[i]\n",
    "        ind = torch.Tensor([ind]).long()\n",
    "        if ind >= embed.shape[0]:\n",
    "            continue\n",
    "        embed = torch.Tensor(embed).unsqueeze(0)\n",
    "\n",
    "        predv, sim = model(embed)\n",
    "        loss = loss_fn(sim, ind)\n",
    "        accum += loss\n",
    "        total_loss += float(loss)\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "            accum.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            accum = 0\n",
    "    print(f'Total loss {epoch}: total_loss')\n",
    "    total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = WordDataset('subdata_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32690125703811646\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    text, embed, ind = test_dataset[i]\n",
    "    embed = torch.Tensor(embed).unsqueeze(0)\n",
    "    predv, sim = model(embed)\n",
    "    predi = sim.max(dim=1).indices[0]\n",
    "    correct += predi == ind\n",
    "print(f'Accuracy: {correct/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
